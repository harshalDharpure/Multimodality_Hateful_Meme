{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOxpe49PrRnwB98AlUKCXxC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalDharpure/Multimodality_Hateful_Meme/blob/main/Bias_train_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf7aNLasHaKs"
      },
      "outputs": [],
      "source": [
        "#Modified for Hindi datasets Prompthate code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import utils\n",
        "import torch.nn.functional as F\n",
        "import config\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from dataset import Multimodal_Data\n",
        "\n",
        "# Import WeightedBCELoss\n",
        "class WeightedBCELoss(nn.Module):\n",
        "    def __init__(self, bias_weight):\n",
        "        super(WeightedBCELoss, self).__init__()\n",
        "        self.bias_weight = bias_weight\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        # Compute binary cross-entropy loss\n",
        "        loss = nn.functional.binary_cross_entropy_with_logits(logits, labels)\n",
        "        loss *= self.bias_weight\n",
        "        return loss\n",
        "\n",
        "def bce_for_loss(logits, labels):\n",
        "    loss = nn.functional.binary_cross_entropy_with_logits(logits, labels)\n",
        "    loss *= labels.size(1)\n",
        "    return loss\n",
        "\n",
        "def compute_auc_score(logits, label):\n",
        "    bz = logits.shape[0]\n",
        "    logits = logits.cpu().numpy()\n",
        "    label = label.cpu().numpy()\n",
        "    auc = roc_auc_score(label, logits, average='weighted') * bz\n",
        "    return auc\n",
        "\n",
        "def compute_score(logits, labels):\n",
        "    logits = torch.max(logits, 1)[1]\n",
        "    one_hot = torch.zeros(*labels.size()).cuda()\n",
        "    one_hot.scatter_(1, logits.view(-1, 1), 1)\n",
        "    score = one_hot * labels\n",
        "    return score.sum().float()\n",
        "\n",
        "def compute_scaler_score(logits, labels):\n",
        "    logits = torch.max(logits, 1)[1]\n",
        "    labels = labels.squeeze(-1)\n",
        "    score = (logits == labels).int()\n",
        "    return score.sum().float()\n",
        "\n",
        "def log_hyperpara(logger, opt):\n",
        "    dic = vars(opt)\n",
        "    for k, v in dic.items():\n",
        "        logger.write(k + ' : ' + str(v)\n",
        "\n",
        "def train_for_epoch(opt, model, train_loader, test_loader):\n",
        "    # Add bias_weight customization here\n",
        "    bias_weight = torch.tensor([1.0, 1.5])  # Adjust bias_weight as needed\n",
        "\n",
        "    if opt.SAVE:\n",
        "        model_path = os.path.join('../models',\n",
        "                                  '_'.join([opt.MODEL, opt.DATASET]))\n",
        "        if not os.path.exists(model_path):\n",
        "            os.mkdir(model_path)\n",
        "\n",
        "    if opt.MULTI_QUERY:\n",
        "        from transformers import RobertaTokenizer\n",
        "        tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "    log_path = os.path.join(opt.DATASET)\n",
        "    if not os.path.exists(log_path):\n",
        "        os.mkdir(log_path)\n",
        "    logger = utils.Logger(os.path.join(log_path, str(opt.SAVE_NUM) + '.txt')\n",
        "    log_hyperpara(logger, opt)\n",
        "    logger.write('Length of training set: %d, length of testing set: %d' %\n",
        "                 (len(train_loader.dataset), len(test_loader.dataset))\n",
        "\n",
        "    if opt.MODEL == 'pbm':\n",
        "        params = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if opt.FIX_LAYERS > 0:\n",
        "                if 'encoder.layer' in n:\n",
        "                    try:\n",
        "                        layer_num = int(n[n.find('encoder.layer') + 14:].split('.')[0])\n",
        "                    except:\n",
        "                        print(n)\n",
        "                        raise Exception(\"\")\n",
        "                    if layer_num >= opt.FIX_LAYERS:\n",
        "                        print('yes', n)\n",
        "                        params[n] = p\n",
        "                    else:\n",
        "                        print('no ', n)\n",
        "                elif 'embeddings' in n:\n",
        "                    print('no ', n)\n",
        "                else:\n",
        "                    print('yes', n)\n",
        "                    params[n] = p\n",
        "            else:\n",
        "                params[n] = p\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in params.items() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": opt.WEIGHT_DECAY,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in params.items() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        optim = AdamW(\n",
        "            optimizer_grouped_parameters,\n",
        "            lr=opt.LR_RATE,\n",
        "            eps=opt.EPS,\n",
        "        )\n",
        "    else:\n",
        "        params = model.parameters()\n",
        "        optim = AdamW(params,\n",
        "                      lr=1e-5,\n",
        "                      eps=1e-8\n",
        "                      )\n",
        "    num_training_steps = len(train_loader) * opt.EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optim,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=num_training_steps)\n",
        "    # Use WeightedBCELoss\n",
        "    loss_fn = WeightedBCELoss(bias_weight)\n",
        "    loss_fct = nn.KLDivLoss(log_target=True)\n",
        "\n",
        "    record_auc = []\n",
        "    record_acc = []\n",
        "\n",
        "    for epoch in range(opt.EPOCHS):\n",
        "        model.train(True)\n",
        "        total_loss = 0.0\n",
        "        scores = 0.0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            cap = batch['cap_tokens'].long().cuda()\n",
        "            label = batch['label'].float().cuda().view(-1, 1)\n",
        "            mask = batch['mask'].cuda()\n",
        "            target = batch['target'].cuda()\n",
        "            feat = None\n",
        "\n",
        "            if opt.MODEL == 'pbm':\n",
        "                mask_pos = batch['mask_pos'].cuda()\n",
        "                logits = model(cap, mask, mask_pos, feat)\n",
        "                if opt.FINE_GRIND:\n",
        "                    attack = batch['attack'].cuda()\n",
        "                    logits[:, 1] = torch.sum(logits[:, 1:], dim=1)\n",
        "                    logits = logits[:, :2]\n",
        "\n",
        "            elif opt.MODEL == 'roberta':\n",
        "                if opt.UNIMODAL == False:\n",
        "                    feat = batch['feat'].cuda()\n",
        "                logits = model(cap, mask, feat)\n",
        "\n",
        "            loss = loss_fn(logits, target)\n",
        "            batch_score = compute_score(logits, target)\n",
        "            scores += batch_score\n",
        "\n",
        "            print ('Epoch:', epoch, 'Iteration:', i, loss.item(), batch_score)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            scheduler.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "            total_loss += loss\n",
        "\n",
        "        model.train(False)\n",
        "        scores /= len(train_loader.dataset)\n",
        "        if opt.MULTI_QUERY == False:\n",
        "            eval_acc, eval_auc = eval_model(opt, model, test_loader)\n",
        "        else:\n",
        "            eval_acc, eval_auc = eval_multi_model(opt, model, tokenizer)\n",
        "        record_auc.append(eval_auc)\n",
        "        record_acc.append(eval_acc)\n",
        "        logger.write('Epoch %d' % (epoch))\n",
        "\n",
        "                logger.write('\\ttrain_loss: %.2f, accuracy: %.2f' % (total_loss,\n",
        "                                                             scores * 100.0))\n",
        "        logger.write('\\tevaluation auc: %.2f, accuracy: %.2f' % (eval_auc,\n",
        "                                                                 eval_acc))\n",
        "\n",
        "    max_idx = sorted(range(len(record_auc),\n",
        "                         key=lambda k: record_auc[k] + record_acc[k],\n",
        "                         reverse=True)[0]\n",
        "    logger.write('Maximum epoch: %d' % (max_idx))\n",
        "    logger.write('\\tevaluation auc: %.2f, accuracy: %.2f' % (record_auc[max_idx],\n",
        "                                                             record_acc[max_idx]))\n",
        "\n",
        "def eval_model(opt, model, test_loader):\n",
        "    scores = 0.0\n",
        "    auc = 0.0\n",
        "    len_data = len(test_loader.dataset)\n",
        "    print ('Length of test set:', len_data)\n",
        "    total_logits = []\n",
        "    total_labels = []\n",
        "    for i, batch in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "            cap = batch['cap_tokens'].long().cuda()\n",
        "            label = batch['label'].float().cuda().view(-1, 1)\n",
        "            mask = batch['mask'].cuda()\n",
        "            target = batch['target'].cuda()\n",
        "            feat = None\n",
        "\n",
        "            if opt.MODEL == 'pbm':\n",
        "                mask_pos = batch['mask_pos'].cuda()\n",
        "                logits = model(cap, mask, mask_pos, feat)\n",
        "                if opt.FINE_GRIND:\n",
        "                    logits[:, 1] = torch.sum(logits[:, 1:], dim=1)\n",
        "                    logits = logits[:, :2]\n",
        "\n",
        "            elif opt.MODEL == 'roberta':\n",
        "                if opt.UNIMODAL == False:\n",
        "                    feat = batch['feat'].cuda()\n",
        "                logits = model(cap, mask, feat)\n",
        "\n",
        "            batch_score = compute_score(logits, target)\n",
        "            scores += batch_score\n",
        "            norm_logits = F.softmax(logits, dim=-1)[:, 1].unsqueeze(-1)\n",
        "\n",
        "            total_logits.append(norm_logits)\n",
        "            total_labels.append(label)\n",
        "    total_logits = torch.cat(total_logits, dim=0)\n",
        "    total_labels = torch.cat(total_labels, dim=0)\n",
        "    print (total_logits.shape, total_labels.shape)\n",
        "    auc = compute_auc_score(total_logits, total_labels)\n",
        "    return scores * 100.0 / len_data, auc * 100.0 / len_data\n",
        "\n",
        "def eval_multi_model(opt, model, tokenizer):\n",
        "    num_queries = opt.NUM_QUERIES\n",
        "    labels_record = {}\n",
        "    logits_record = {}\n",
        "    prob_record = {}\n",
        "    for k in range(num_queries):\n",
        "        test_set = Multimodal_Data(opt, tokenizer, opt.DATASET, 'test')\n",
        "        test_loader = DataLoader(test_set,\n",
        "                                opt.BATCH_SIZE,\n",
        "                                shuffle=False,\n",
        "                                num_workers=1)\n",
        "        len_data = len(test_loader.dataset)\n",
        "        print ('Length of test set:', len_data, 'Query:', k)\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            with torch.no_grad():\n",
        "                cap = batch['cap_tokens'].long().cuda()\n",
        "                label = batch['label'].float().cuda().view(-1, 1)\n",
        "                mask = batch['mask'].cuda()\n",
        "                mask_pos = batch['mask_pos'].cuda()\n",
        "                logits = model(cap, mask, mask_pos)\n",
        "                if opt.FINE_GRIND:\n",
        "                    logits[:, 1] = torch.sum(logits[:, 1:], dim=1)\n",
        "                    logits = logits[:, :2]\n",
        "                target = batch['target'].cuda()\n",
        "                img = batch['img']\n",
        "                norm_prob = F.softmax(logits, dim=-1)\n",
        "                norm_logits = norm_prob[:, 1].unsqueeze(-1)\n",
        "\n",
        "                bz = cap.shape[0]\n",
        "                for j in range(bz):\n",
        "                    cur_img = img[j]\n",
        "                    cur_logits = norm_logits[j:j+1]\n",
        "                    cur_prob = norm_prob[j:j+1]\n",
        "                    if k == 0:\n",
        "                        cur_label = label[j:j+1]\n",
        "                        labels_record[cur_img] = cur_label\n",
        "                        logits_record[cur_img] = cur_logits\n",
        "                        prob_record[cur_img] = cur_prob\n",
        "                    else:\n",
        "                        logits_record[cur_img] += cur_logits\n",
        "                        prob_record[cur_img] += cur_prob\n",
        "    labels = []\n",
        "    logits = []\n",
        "    probs = []\n",
        "    for name in labels_record.keys():\n",
        "        labels.append(labels_record[name])\n",
        "        logits.append(logits_record[name] / num_queries)\n",
        "        probs.append(prob_record[name] / num_queries)\n",
        "\n",
        "    logits = torch.cat(logits, dim=0)\n",
        "    labels = torch.cat(labels, dim=0)\n",
        "    probs = torch.cat(probs, dim=0)\n",
        "    scores = compute_scaler_score(probs, labels)\n",
        "    auc = compute_auc_score(logits, labels)\n",
        "    return scores * 100.0 / len_data, auc * 100.0 / len_data\n"
      ],
      "metadata": {
        "id": "fNKb9bx3JLGI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}