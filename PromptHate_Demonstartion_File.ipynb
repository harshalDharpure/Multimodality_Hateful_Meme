{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPup0QCNGMIIWBFbF9ii6ZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshalDharpure/Multimodality_Hateful_Meme/blob/main/PromptHate_Demonstartion_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf7aNLasHaKs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import config\n",
        "import os\n",
        "from train import train_for_epoch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer\n",
        "from rela_encoder import Rela_Module\n",
        "v_dim = 512  # Replace with the actual value for v_dim\n",
        "hid_dim = 256  # Replace with the actual value for hid_dim\n",
        "h = 8  # Replace with the actual value for h\n",
        "mid_dim = 1024  # Replace with the actual value for mid_dim\n",
        "num_layers = 4  # Replace with the actual value for num_layers\n",
        "dropout = 0.1\n",
        "batch_size = 32  # Replace with the actual batch size you intend to use\n",
        "seq_len = 20  # Replace with the actual sequence length\n",
        "v_dim = 512\n",
        "d_model=256\n",
        "from dataset import Multimodal_Data\n",
        "\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    opt=config.parse_opt()\n",
        "    ##nvidiatorch.cuda.set_device(opt.CUDA_DEVICE)\n",
        "    set_seed(opt.SEED)\n",
        "\n",
        "\n",
        "    # Create tokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "    constructor='build_baseline'\n",
        "    if opt.MODEL=='pbm':\n",
        "        from dataset import Multimodal_Data\n",
        "        import baseline\n",
        "        train_set=Multimodal_Data(opt,tokenizer,opt.DATASET,'train',opt.SEED-1111)\n",
        "        test_set=Multimodal_Data(opt,tokenizer,opt.DATASET,'test')\n",
        "        label_list=[train_set.label_mapping_id[i] for i in train_set.label_mapping_word.keys()]\n",
        "        model=getattr(baseline,constructor)(opt, label_list).cuda()\n",
        "    else:\n",
        "        from roberta_dataset import Roberta_Data\n",
        "        import roberta_baseline\n",
        "        train_set=Roberta_Data(opt,tokenizer,opt.DATASET,'train',opt.SEED-1111)\n",
        "        test_set=Roberta_Data(opt,tokenizer,opt.DATASET,'test')\n",
        "        model=getattr(roberta_baseline,constructor)(opt).cuda()\n",
        "\n",
        "\n",
        "\n",
        "    rela_module = Rela_Module(v_dim, hid_dim, h, mid_dim, num_layers, dropout)\n",
        "    img = torch.randn(batch_size, seq_len, v_dim)  # Replace with your actual input\n",
        "    cap = torch.randn(batch_size, seq_len, d_model)  # Replace with your actual input\n",
        "\n",
        "    # Call the forward method and get the output\n",
        "    output = rela_module(img, cap)\n",
        "\n",
        "    # Print the output tensor\n",
        "    print(\"Output Tensor:\", output)\n",
        "dataset=\"mem\"\n",
        "train_set = Multimodal_Data(opt, tokenizer, dataset, 'train', few_shot_index=0)\n",
        "for i, batch in enumerate(train_set):\n",
        "    print(f\"Sample {i + 1}:\\n\")\n",
        "    print(\"Sent:\", batch[\"sent\"])\n",
        "    print(\"Mask:\", batch[\"mask\"])\n",
        "    print(\"Image:\", batch[\"img\"])\n",
        "    print(\"Target:\", batch[\"target\"])\n",
        "    print(\"Cap Tokens:\", batch[\"cap_tokens\"])\n",
        "    print(\"Mask Pos:\", batch[\"mask_pos\"])\n",
        "    print(\"Label:\", batch[\"label\"])\n",
        "    if opt.FINE_GRIND:\n",
        "        print(\"Attack:\", batch[\"attack\"])\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    # train_loader=DataLoader(train_set,\n",
        "    #                         opt.BATCH_SIZE,\n",
        "    #                         shuffle=True,\n",
        "    #                         num_workers=1)\n",
        "    # test_loader=DataLoader(test_set,\n",
        "    #                        opt.BATCH_SIZE,\n",
        "    #                        shuffle=False,\n",
        "    #                        num_workers=1)\n",
        "    # train_for_epoch(opt,model,train_loader,test_loader)\n",
        "# Create an instance of Rela_Module\n",
        "v_dim = 512  # Replace with your actual input dimensions\n",
        "hid_dim = 256  # Replace with your actual dimensions\n",
        "h = 4  # Replace with the number of heads you want\n",
        "mid_dim = 1024  # Replace with your desired dimensions\n",
        "num_layers = 2  # Replace with the number of layers you want\n",
        "dropout = 0.1  # Replace with your desired dropout rate\n",
        "\n",
        "rela_module = Rela_Module(v_dim, hid_dim, h, mid_dim, num_layers, dropout)\n",
        "\n",
        "# Generate some sample input data\n",
        "# Replace this with your actual input data\n",
        "sample_img = torch.randn(1, v_dim)\n",
        "sample_cap = torch.randn(1, v_dim)\n",
        "sample_obj_mask = torch.randn(1, v_dim)  # You need to define the mask according to your needs\n",
        "\n",
        "# Call the forward method\n",
        "output = rela_module(sample_img, sample_cap, sample_obj_mask)\n",
        "\n",
        "# Print the output\n",
        "print(\"Output of Rela_Module:\")\n",
        "print(output)\n",
        "\n",
        "exit(0)\n",
        ""
      ]
    }
  ]
}